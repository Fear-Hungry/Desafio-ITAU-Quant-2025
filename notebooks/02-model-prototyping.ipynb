{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prototyping - Testing Estimators and Strategies\n",
    "\n",
    "Este notebook demonstra como testar diferentes estimadores e estratégias de otimização.\n",
    "\n",
    "**Objetivos:**\n",
    "1. Testar estimadores robustos de μ e Σ\n",
    "2. Comparar métodos de shrinkage (Ledoit-Wolf, Nonlinear, Tyler)\n",
    "3. Prototipar estratégias de otimização\n",
    "4. Visualizar fronteira eficiente\n",
    "5. Avaliar sensibilidade a parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✅ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados (usamos cache do notebook anterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration and data (similar to notebook 01)\n",
    "from itau_quant.config import load_config, UniverseConfig, PortfolioConfig\n",
    "import yfinance as yf\n",
    "\n",
    "# Load configs\n",
    "universe_config = load_config(\n",
    "    str(project_root / 'configs' / 'universe_arara.yaml'),\n",
    "    UniverseConfig\n",
    ")\n",
    "portfolio_config = load_config(\n",
    "    str(project_root / 'configs' / 'portfolio_arara_basic.yaml'),\n",
    "    PortfolioConfig\n",
    ")\n",
    "\n",
    "# Download sample data\n",
    "end_date = datetime.today()\n",
    "start_date = end_date - timedelta(days=365 * 2)  # 2 years for faster testing\n",
    "\n",
    "data = yf.download(\n",
    "    tickers=universe_config.tickers[:10],  # Use subset for prototyping\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    progress=False,\n",
    "    auto_adjust=True\n",
    ")\n",
    "\n",
    "if isinstance(data.columns, pd.MultiIndex):\n",
    "    prices = data['Close']\n",
    "else:\n",
    "    prices = data\n",
    "\n",
    "prices = prices.dropna(how='all').ffill().bfill()\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "print(f\"Data loaded: {len(returns)} days, {len(returns.columns)} assets\")\n",
    "print(f\"Assets: {', '.join(returns.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testar Estimadores de Retornos Esperados (μ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itau_quant.estimators.mu import mean_return, huber_mean\n",
    "\n",
    "# Simple mean\n",
    "mu_simple = mean_return(returns, method='simple')\n",
    "\n",
    "# Huber robust mean\n",
    "mu_huber, weights_huber = huber_mean(returns, c=1.5)\n",
    "\n",
    "# Compare\n",
    "comparison = pd.DataFrame({\n",
    "    'Simple Mean': mu_simple * 252,\n",
    "    'Huber Mean': mu_huber * 252,\n",
    "    'Difference': (mu_huber - mu_simple) * 252\n",
    "})\n",
    "\n",
    "print(\"Expected Returns Comparison (annualized):\")\n",
    "print(comparison.to_string())\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(comparison))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, comparison['Simple Mean'], width, label='Simple Mean', alpha=0.8)\n",
    "ax.bar(x + width/2, comparison['Huber Mean'], width, label='Huber Mean', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Asset', fontsize=11)\n",
    "ax.set_ylabel('Expected Return (annualized)', fontsize=11)\n",
    "ax.set_title('Expected Returns: Simple vs Huber', fontsize=13, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison.index, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testar Estimadores de Covariância (Σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itau_quant.estimators.cov import (\n",
    "    sample_cov,\n",
    "    ledoit_wolf_shrinkage,\n",
    "    nonlinear_shrinkage,\n",
    "    tyler_m_estimator\n",
    ")\n",
    "\n",
    "# Test different covariance estimators\n",
    "cov_sample = sample_cov(returns)\n",
    "cov_lw, shrinkage_lw = ledoit_wolf_shrinkage(returns)\n",
    "cov_nls = nonlinear_shrinkage(returns)\n",
    "cov_tyler = tyler_m_estimator(returns, max_iter=50)\n",
    "\n",
    "print(f\"Ledoit-Wolf shrinkage parameter: {shrinkage_lw:.4f}\")\n",
    "print(f\"\\\\nCondition numbers:\")\n",
    "print(f\"  Sample cov:    {np.linalg.cond(cov_sample.values):.2e}\")\n",
    "print(f\"  Ledoit-Wolf:   {np.linalg.cond(cov_lw.values):.2e}\")\n",
    "print(f\"  Nonlinear:     {np.linalg.cond(cov_nls.values):.2e}\")\n",
    "print(f\"  Tyler:         {np.linalg.cond(cov_tyler.values):.2e}\")\n",
    "\n",
    "# Compare diagonal elements (variances)\n",
    "var_comparison = pd.DataFrame({\n",
    "    'Sample': np.diag(cov_sample.values) * 252,\n",
    "    'Ledoit-Wolf': np.diag(cov_lw.values) * 252,\n",
    "    'Nonlinear': np.diag(cov_nls.values) * 252,\n",
    "    'Tyler': np.diag(cov_tyler.values) * 252\n",
    "}, index=cov_sample.index)\n",
    "\n",
    "print(\"\\\\nVariances (annualized):\")\n",
    "print(var_comparison.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testar Otimização Mean-Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itau_quant.optimization.core.mv_qp import solve_mean_variance, MeanVarianceConfig\n",
    "\n",
    "# Setup optimization config\n",
    "config = MeanVarianceConfig(\n",
    "    risk_aversion=portfolio_config.risk_aversion,\n",
    "    turnover_penalty=portfolio_config.turnover_penalty,\n",
    "    lower_bounds=pd.Series(0.0, index=returns.columns),\n",
    "    upper_bounds=pd.Series(portfolio_config.max_position, index=returns.columns),\n",
    "    previous_weights=pd.Series(0.0, index=returns.columns),\n",
    "    solver=\"CLARABEL\"\n",
    ")\n",
    "\n",
    "# Solve with Ledoit-Wolf covariance\n",
    "mu_annual = mu_simple * 252\n",
    "cov_annual = cov_lw * 252\n",
    "\n",
    "result = solve_mean_variance(mu_annual, cov_annual, config)\n",
    "\n",
    "if result.summary.is_optimal():\n",
    "    print(\"✅ Optimization successful!\")\n",
    "    print(f\"Status: {result.summary.status}\")\n",
    "    print(f\"Runtime: {result.summary.runtime:.3f}s\")\n",
    "    \n",
    "    weights = result.weights\n",
    "    active_weights = weights[weights > 0.001].sort_values(ascending=False)\n",
    "    \n",
    "    print(f\"\\\\nPortfolio Weights:\")\n",
    "    for ticker, w in active_weights.items():\n",
    "        print(f\"  {ticker}: {w:.2%}\")\n",
    "    \n",
    "    # Portfolio metrics\n",
    "    port_return = float(mu_annual @ weights)\n",
    "    port_vol = float(np.sqrt(weights @ cov_annual @ weights))\n",
    "    sharpe = port_return / port_vol\n",
    "    \n",
    "    print(f\"\\\\nPortfolio Metrics (ex-ante):\")\n",
    "    print(f\"  Expected Return: {port_return:+.2%}\")\n",
    "    print(f\"  Volatility:      {port_vol:.2%}\")\n",
    "    print(f\"  Sharpe Ratio:    {sharpe:.2f}\")\n",
    "else:\n",
    "    print(f\"❌ Optimization failed: {result.summary.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparar Estratégias Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itau_quant.optimization.core.risk_parity import solve_risk_parity\n",
    "\n",
    "# 1/N (Equal-weight)\n",
    "w_equal = pd.Series(1/len(returns.columns), index=returns.columns)\n",
    "\n",
    "# Risk Parity\n",
    "w_rp = solve_risk_parity(cov_lw)\n",
    "\n",
    "# Mean-Variance (já calculado)\n",
    "w_mv = weights\n",
    "\n",
    "# Compare portfolios\n",
    "strategies = {\n",
    "    '1/N': w_equal,\n",
    "    'Risk Parity': w_rp,\n",
    "    'Mean-Variance': w_mv\n",
    "}\n",
    "\n",
    "metrics = []\n",
    "for name, w in strategies.items():\n",
    "    ret = float(mu_annual @ w)\n",
    "    vol = float(np.sqrt(w @ cov_annual @ w))\n",
    "    sr = ret / vol if vol > 0 else 0\n",
    "    metrics.append({\n",
    "        'Strategy': name,\n",
    "        'Return': ret,\n",
    "        'Volatility': vol,\n",
    "        'Sharpe': sr\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics).set_index('Strategy')\n",
    "print(\"Strategy Comparison (ex-ante):\")\n",
    "print(metrics_df.to_string())\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(metrics_df['Volatility'], metrics_df['Return'], s=200, alpha=0.7)\n",
    "\n",
    "for idx, row in metrics_df.iterrows():\n",
    "    ax.annotate(idx, (row['Volatility'], row['Return']), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=11)\n",
    "\n",
    "ax.set_xlabel('Volatility (annualized)', fontsize=12)\n",
    "ax.set_ylabel('Expected Return (annualized)', fontsize=12)\n",
    "ax.set_title('Risk-Return Profile: Strategy Comparison', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "Este notebook demonstrou:\n",
    "\n",
    "1. **Estimadores de μ**: Comparação entre média simples e Huber robusto\n",
    "2. **Estimadores de Σ**: Teste de diferentes métodos de shrinkage\n",
    "3. **Otimização MV**: Implementação funcional com constraints\n",
    "4. **Estratégias baseline**: Comparação de 1/N, Risk Parity e Mean-Variance\n",
    "\n",
    "**Próximos passos:**\n",
    "- Ver notebook `03-results-analysis.ipynb` para análise de backtests completos\n",
    "- Experimentar diferentes valores de risk_aversion e shrinkage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
