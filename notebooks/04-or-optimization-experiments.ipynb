{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experimentos (OR/Otimização) — Mean-CVaR + Turnover\n",
        "\n",
        "Notebook central do artigo acadêmico (Pesquisa Operacional / Otimização).\n",
        "\n",
        "O objetivo é gerar, **dentro do próprio notebook**, os principais artefatos do paper:\n",
        "\n",
        "- **Tabela principal**: retorno/risco/CVaR/drawdown/turnover/custos.\n",
        "- **Figura de trade-off**: retorno vs risco de cauda (CVaR).\n",
        "- **Sensibilidade**: varredura de τ (limite de CVaR) e penalidade de turnover.\n",
        "- **Estresse**: métricas por subperíodo (COVID/2022 etc.).\n",
        "- **Diagnóstico do solver**: status, tempo e resíduos (importante em OR).\n",
        "\n",
        "## Convenções (CVaR)\n",
        "\n",
        "- No LP de mean-CVaR (`solve_cvar_lp`), o CVaR é modelado sobre **perdas** (valor positivo).\n",
        "- Na avaliação OOS (`arara_quant.evaluation.oos`), `cvar_95` é a média dos **piores retornos** (valor negativo) e `cvar_95_annual = cvar_95 × √252`.\n",
        "- Para o paper, use normalmente **perda**: `cvar_loss_95_annual = -cvar_95_annual`.\n",
        "\n",
        "Referência: `docs/CVAR_CONVENTION.md`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import platform\n",
        "import subprocess\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from itertools import product\n",
        "from pathlib import Path\n",
        "from typing import Any\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "REPO_ROOT = Path.cwd().resolve()\n",
        "if (REPO_ROOT / \"src\").exists():\n",
        "    sys.path.insert(0, str(REPO_ROOT / \"src\"))\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 140)\n",
        "np.set_printoptions(precision=6, suppress=True)\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
        "\n",
        "\n",
        "def _git_head() -> str:\n",
        "    try:\n",
        "        return subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"], text=True).strip()\n",
        "    except Exception:\n",
        "        return \"unknown\"\n",
        "\n",
        "\n",
        "def _env_snapshot() -> dict[str, Any]:\n",
        "    return {\n",
        "        \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "        \"git\": _git_head(),\n",
        "        \"python\": sys.version.split()[0],\n",
        "        \"platform\": platform.platform(),\n",
        "        \"numpy\": np.__version__,\n",
        "        \"pandas\": pd.__version__,\n",
        "    }\n",
        "\n",
        "\n",
        "env = _env_snapshot()\n",
        "env\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Dados\n",
        "\n",
        "Este notebook usa a matriz de retornos `data/processed/returns_arara.parquet`.\n",
        "\n",
        "Se ainda não existir:\n",
        "```bash\n",
        "poetry run python scripts/run_01_data_pipeline.py --force-download --start 2010-01-01\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "returns_path = REPO_ROOT / \"data/processed/returns_arara.parquet\"\n",
        "if not returns_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Arquivo não encontrado: {returns_path}. Rode scripts/run_01_data_pipeline.py para gerar.\"\n",
        "    )\n",
        "\n",
        "returns_raw = pd.read_parquet(returns_path).sort_index().astype(float)\n",
        "\n",
        "# Filtro mínimo de observações por ativo (alinha com scripts/research/run_cvar_tail_experiment.py)\n",
        "TRAIN_WINDOW = 252\n",
        "MIN_OBS = TRAIN_WINDOW + 60\n",
        "valid_cols = [c for c in returns_raw.columns if returns_raw[c].count() >= MIN_OBS]\n",
        "\n",
        "returns = returns_raw[valid_cols].fillna(0.0)\n",
        "\n",
        "summary = {\n",
        "    \"rows\": int(len(returns)),\n",
        "    \"assets\": int(returns.shape[1]),\n",
        "    \"start\": str(returns.index.min().date()),\n",
        "    \"end\": str(returns.index.max().date()),\n",
        "    \"min_obs_filter\": int(MIN_OBS),\n",
        "    \"missing_rate_raw\": float(returns_raw.isna().mean().mean()),\n",
        "}\n",
        "\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1) Sanity checks do dataset (para seção de dados)\n",
        "\n",
        "- Número de ativos elegíveis\n",
        "- Distribuição de observações por ativo\n",
        "- Checagem de magnitude de retornos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "obs_per_asset = returns_raw[valid_cols].count().sort_values(ascending=False)\n",
        "describe = obs_per_asset.describe().to_frame(name=\"obs\")\n",
        "describe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.hist(obs_per_asset.values, bins=20, alpha=0.85)\n",
        "ax.set_title(\"Observações por ativo (após filtro min_obs)\")\n",
        "ax.set_xlabel(\"# observações\")\n",
        "ax.set_ylabel(\"# ativos\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q = returns.stack().quantile([0.001, 0.01, 0.5, 0.99, 0.999]).to_frame(name=\"return\")\n",
        "q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Desenho experimental (walk-forward)\n",
        "\n",
        "Configuração base (padrões do repo):\n",
        "- `train=252`, `test=21`, `purge=5`, `embargo=5`\n",
        "- custos lineares: `30 bps` (aplicado no rebalance)\n",
        "- box constraints: `0 ≤ w_i ≤ max_position`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEST_WINDOW = 21\n",
        "PURGE_WINDOW = 5\n",
        "EMBARGO_WINDOW = 5\n",
        "\n",
        "COSTS_BPS = 30.0\n",
        "MAX_POSITION = 0.12\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "BOOTSTRAP_ITERATIONS = 200  # use 0 para rodar mais rápido\n",
        "CONFIDENCE = 0.95\n",
        "BLOCK_SIZE = 21\n",
        "\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        \"train_window\": [TRAIN_WINDOW],\n",
        "        \"test_window\": [TEST_WINDOW],\n",
        "        \"purge_window\": [PURGE_WINDOW],\n",
        "        \"embargo_window\": [EMBARGO_WINDOW],\n",
        "        \"costs_bps\": [COSTS_BPS],\n",
        "        \"max_position\": [MAX_POSITION],\n",
        "        \"bootstrap_iterations\": [BOOTSTRAP_ITERATIONS],\n",
        "        \"block_size\": [BLOCK_SIZE],\n",
        "        \"random_state\": [RANDOM_STATE],\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Estratégias\n",
        "\n",
        "Baselines (para comparação em OR):\n",
        "- 1/N (`equal_weight`)\n",
        "- Risk Parity (`risk_parity`)\n",
        "- MV com shrink conservador (`shrunk_mv`)\n",
        "\n",
        "Proposto:\n",
        "- Mean-CVaR (LP) com **turnover cap/penalty**, em dois modos:\n",
        "  1) `mean_cvar_target`: retorno-alvo + penalidade de CVaR\n",
        "  2) `mean_cvar_limit`: limite duro de CVaR (perda) + objetivo retorno - λ·CVaR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from arara_quant.evaluation.oos import StrategySpec, compare_baselines, default_strategies, stress_test\n",
        "from arara_quant.optimization.core.cvar_lp import CvarConfig, solve_cvar_lp\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class CvarSpec:\n",
        "    name: str\n",
        "    alpha: float\n",
        "    risk_aversion: float\n",
        "    max_position: float\n",
        "    turnover_penalty: float\n",
        "    turnover_cap: float | None\n",
        "    target_return: float | None\n",
        "    max_cvar_loss: float | None\n",
        "    solver: str\n",
        "\n",
        "\n",
        "def _equal_weight(train_returns: pd.DataFrame) -> pd.Series:\n",
        "    cols = train_returns.columns\n",
        "    if len(cols) == 0:\n",
        "        return pd.Series(dtype=float)\n",
        "    return pd.Series(1.0 / len(cols), index=cols, dtype=float)\n",
        "\n",
        "\n",
        "def _prepare_window(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Mantém o padrão do script de pesquisa: se houver NaNs, remove linhas; se esvaziar, zera.\n",
        "    cleaned = data.dropna(axis=0, how=\"any\")\n",
        "    if cleaned.empty:\n",
        "        return data.fillna(0.0)\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "def build_mean_cvar_strategy(spec: CvarSpec, *, diagnostics: list[dict[str, Any]]) -> StrategySpec:\n",
        "    def builder(train_returns: pd.DataFrame, prev_weights: pd.Series | None) -> pd.Series:\n",
        "        window = _prepare_window(train_returns)\n",
        "        if window.empty:\n",
        "            diagnostics.append({\"status\": \"empty_window\", \"train_end\": None})\n",
        "            return _equal_weight(train_returns)\n",
        "\n",
        "        expected = window.mean()\n",
        "        assets = expected.index\n",
        "\n",
        "        prev = pd.Series(0.0, index=assets, dtype=float)\n",
        "        if prev_weights is not None:\n",
        "            prev = prev_weights.reindex(assets).fillna(0.0).astype(float)\n",
        "\n",
        "        config = CvarConfig(\n",
        "            alpha=spec.alpha,\n",
        "            risk_aversion=spec.risk_aversion,\n",
        "            long_only=True,\n",
        "            lower_bounds=pd.Series(0.0, index=assets, dtype=float),\n",
        "            upper_bounds=pd.Series(spec.max_position, index=assets, dtype=float),\n",
        "            turnover_penalty=spec.turnover_penalty,\n",
        "            turnover_cap=spec.turnover_cap,\n",
        "            previous_weights=prev,\n",
        "            target_return=spec.target_return,\n",
        "            max_cvar=spec.max_cvar_loss,\n",
        "            solver=spec.solver,\n",
        "            solver_kwargs={\"max_iters\": 10_000},\n",
        "        )\n",
        "\n",
        "        record: dict[str, Any] = {\n",
        "            \"train_end\": str(window.index.max().date()) if len(window.index) else None,\n",
        "            \"n_assets\": int(len(assets)),\n",
        "            \"n_scenarios\": int(len(window)),\n",
        "            \"alpha\": float(spec.alpha),\n",
        "            \"risk_aversion\": float(spec.risk_aversion),\n",
        "            \"turnover_penalty\": float(spec.turnover_penalty),\n",
        "            \"turnover_cap\": None if spec.turnover_cap is None else float(spec.turnover_cap),\n",
        "            \"target_return\": None if spec.target_return is None else float(spec.target_return),\n",
        "            \"max_cvar_loss\": None if spec.max_cvar_loss is None else float(spec.max_cvar_loss),\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            result = solve_cvar_lp(window, expected, config)\n",
        "            record.update(\n",
        "                {\n",
        "                    \"status\": result.summary.status,\n",
        "                    \"solver\": result.summary.solver,\n",
        "                    \"runtime\": result.summary.runtime,\n",
        "                    \"objective\": result.summary.value,\n",
        "                    \"primal_residual\": result.summary.primal_residual,\n",
        "                    \"dual_residual\": result.summary.dual_residual,\n",
        "                    \"expected_return\": result.expected_return,\n",
        "                    \"cvar_loss\": result.cvar,\n",
        "                    \"var_loss\": result.var,\n",
        "                    \"turnover\": result.turnover,\n",
        "                }\n",
        "            )\n",
        "            weights = result.weights.reindex(assets).fillna(0.0)\n",
        "        except Exception as exc:\n",
        "            record.update({\"status\": \"exception\", \"error\": str(exc)})\n",
        "            diagnostics.append(record)\n",
        "            return _equal_weight(train_returns)\n",
        "\n",
        "        diagnostics.append(record)\n",
        "\n",
        "        weights = weights.clip(lower=0.0, upper=spec.max_position)\n",
        "        total = float(weights.sum())\n",
        "        if total <= 0:\n",
        "            return _equal_weight(train_returns)\n",
        "        return weights / total\n",
        "\n",
        "    return StrategySpec(spec.name, builder)\n",
        "\n",
        "\n",
        "base_strategies = default_strategies(max_position=MAX_POSITION)\n",
        "base_strategies = [s for s in base_strategies if s.name in {\"equal_weight\", \"risk_parity\", \"shrunk_mv\"}]\n",
        "\n",
        "diag_target: list[dict[str, Any]] = []\n",
        "diag_limit: list[dict[str, Any]] = []\n",
        "\n",
        "spec_target = CvarSpec(\n",
        "    name=\"mean_cvar_target\",\n",
        "    alpha=0.95,\n",
        "    risk_aversion=2.5,\n",
        "    max_position=MAX_POSITION,\n",
        "    turnover_penalty=0.02,\n",
        "    turnover_cap=0.20,\n",
        "    target_return=0.0004,  # ~10% a.a. (aprox.)\n",
        "    max_cvar_loss=None,\n",
        "    solver=\"CLARABEL\",\n",
        ")\n",
        "\n",
        "spec_limit = CvarSpec(\n",
        "    name=\"mean_cvar_limit\",\n",
        "    alpha=0.95,\n",
        "    risk_aversion=1.5,\n",
        "    max_position=MAX_POSITION,\n",
        "    turnover_penalty=0.02,\n",
        "    turnover_cap=0.20,\n",
        "    target_return=None,\n",
        "    max_cvar_loss=0.06,  # CVaR(loss) diário <= 6%\n",
        "    solver=\"CLARABEL\",\n",
        ")\n",
        "\n",
        "strategies = [\n",
        "    *base_strategies,\n",
        "    build_mean_cvar_strategy(spec_target, diagnostics=diag_target),\n",
        "    build_mean_cvar_strategy(spec_limit, diagnostics=diag_limit),\n",
        "]\n",
        "\n",
        "[s.name for s in strategies]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1) Variantes do mean-CVaR (paper) e regime-switching\n",
        "\n",
        "O PDF propõe comparar duas formulações principais:\n",
        "\n",
        "- **CVaR como restrição:** maximizar retorno sujeito a CVaR(loss) ≤ τ.\n",
        "- **CVaR no objetivo:** maximizar retorno − λ·CVaR(loss).\n",
        "\n",
        "E também um **regime-switching simples** (proxy interno por volatilidade; opcionalmente VIX):\n",
        "- regime “normal” → MV (proxy) para capturar bull markets;\n",
        "- regime “estresse” → mean-CVaR para proteção de cauda.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variantes do paper (além das duas já definidas acima)\n",
        "diag_constraint: list[dict[str, Any]] = []\n",
        "diag_objective: list[dict[str, Any]] = []\n",
        "\n",
        "# (A) CVaR como restrição: maximize retorno sob CVaR(loss) <= tau\n",
        "spec_constraint = CvarSpec(\n",
        "    name=\"mean_cvar_constraint\",\n",
        "    alpha=0.95,\n",
        "    risk_aversion=0.0,\n",
        "    max_position=MAX_POSITION,\n",
        "    turnover_penalty=0.02,\n",
        "    turnover_cap=0.20,\n",
        "    target_return=None,\n",
        "    max_cvar_loss=0.06,\n",
        "    solver=\"CLARABEL\",\n",
        ")\n",
        "\n",
        "# (B) CVaR no objetivo: maximize retorno - lambda * CVaR(loss)\n",
        "spec_objective = CvarSpec(\n",
        "    name=\"mean_cvar_objective\",\n",
        "    alpha=0.95,\n",
        "    risk_aversion=2.5,\n",
        "    max_position=MAX_POSITION,\n",
        "    turnover_penalty=0.02,\n",
        "    turnover_cap=0.20,\n",
        "    target_return=None,\n",
        "    max_cvar_loss=None,\n",
        "    solver=\"CLARABEL\",\n",
        ")\n",
        "\n",
        "cvar_constraint = build_mean_cvar_strategy(spec_constraint, diagnostics=diag_constraint)\n",
        "cvar_objective = build_mean_cvar_strategy(spec_objective, diagnostics=diag_objective)\n",
        "\n",
        "# Regime-switching (proxy interno; opcional: VIX)\n",
        "USE_VIX_SIGNAL = False\n",
        "VIX_THRESHOLD = 30.0\n",
        "VOL_THRESHOLD = 0.20  # 20% a.a. (proxy interno)\n",
        "\n",
        "vix_close: pd.Series | None = None\n",
        "if USE_VIX_SIGNAL:\n",
        "    import yfinance as yf\n",
        "\n",
        "    vix_df = yf.download(\n",
        "        \"^VIX\",\n",
        "        start=str(returns.index.min().date()),\n",
        "        end=str(returns.index.max().date()),\n",
        "        progress=False,\n",
        "        auto_adjust=True,\n",
        "    )\n",
        "    if isinstance(vix_df.columns, pd.MultiIndex):\n",
        "        if \"Close\" in vix_df.columns.get_level_values(0):\n",
        "            vix_close = vix_df[\"Close\"].iloc[:, 0]\n",
        "    else:\n",
        "        if \"Close\" in vix_df.columns:\n",
        "            vix_close = vix_df[\"Close\"]\n",
        "    if vix_close is not None:\n",
        "        vix_close = vix_close.dropna().sort_index()\n",
        "\n",
        "regime_log: list[dict[str, Any]] = []\n",
        "\n",
        "from arara_quant.estimators.cov import ledoit_wolf_shrinkage\n",
        "from arara_quant.estimators.mu import shrunk_mean\n",
        "from arara_quant.optimization.core.mv_qp import MeanVarianceConfig, solve_mean_variance\n",
        "\n",
        "\n",
        "def _signal_from_train(train_returns: pd.DataFrame) -> tuple[str, float, bool]:\n",
        "    train_end = train_returns.index.max()\n",
        "\n",
        "    if vix_close is not None and not vix_close.empty:\n",
        "        value = float(vix_close.asof(train_end))\n",
        "        return \"vix\", value, value >= VIX_THRESHOLD\n",
        "\n",
        "    proxy = (\n",
        "        train_returns[\"SPY\"]\n",
        "        if \"SPY\" in train_returns.columns\n",
        "        else train_returns.mean(axis=1)\n",
        "    )\n",
        "    vol = float(proxy.tail(21).std(ddof=1) * np.sqrt(252.0))\n",
        "    return \"realized_vol\", vol, vol >= VOL_THRESHOLD\n",
        "\n",
        "\n",
        "def _mv_shrunk_builder(train_returns: pd.DataFrame, prev_weights: pd.Series | None) -> pd.Series:\n",
        "    assets = train_returns.columns\n",
        "    mu_daily = shrunk_mean(train_returns, strength=0.5, prior=0.0)\n",
        "    mu = mu_daily * 252.0\n",
        "\n",
        "    cov_daily, _ = ledoit_wolf_shrinkage(train_returns)\n",
        "    cov = cov_daily * 252.0\n",
        "\n",
        "    prev = pd.Series(0.0, index=assets, dtype=float)\n",
        "    if prev_weights is not None:\n",
        "        prev = prev_weights.reindex(assets).fillna(0.0).astype(float)\n",
        "\n",
        "    bounds = pd.Series(MAX_POSITION, index=assets, dtype=float)\n",
        "    config = MeanVarianceConfig(\n",
        "        risk_aversion=4.0,\n",
        "        turnover_penalty=0.0,\n",
        "        turnover_cap=None,\n",
        "        lower_bounds=pd.Series(0.0, index=assets, dtype=float),\n",
        "        upper_bounds=bounds,\n",
        "        previous_weights=prev,\n",
        "        cost_vector=None,\n",
        "        solver=\"CLARABEL\",\n",
        "    )\n",
        "    result = solve_mean_variance(mu, cov, config)\n",
        "\n",
        "    weights = (\n",
        "        result.weights.reindex(assets)\n",
        "        .fillna(0.0)\n",
        "        .clip(lower=0.0, upper=MAX_POSITION)\n",
        "    )\n",
        "    total = float(weights.sum())\n",
        "    if total <= 0:\n",
        "        return _equal_weight(train_returns)\n",
        "    return weights / total\n",
        "\n",
        "\n",
        "def _regime_switch(train_returns: pd.DataFrame, prev_weights: pd.Series | None) -> pd.Series:\n",
        "    signal, value, stressed = _signal_from_train(train_returns)\n",
        "\n",
        "    if stressed:\n",
        "        chosen = \"mean_cvar_constraint\"\n",
        "        weights = cvar_constraint.builder(train_returns, prev_weights)\n",
        "    else:\n",
        "        chosen = \"shrunk_mv_proxy\"\n",
        "        weights = _mv_shrunk_builder(train_returns, prev_weights)\n",
        "\n",
        "    regime_log.append(\n",
        "        {\n",
        "            \"train_end\": str(train_returns.index.max().date()),\n",
        "            \"signal\": signal,\n",
        "            \"signal_value\": float(value),\n",
        "            \"stressed\": bool(stressed),\n",
        "            \"chosen\": chosen,\n",
        "        }\n",
        "    )\n",
        "    return weights\n",
        "\n",
        "\n",
        "regime_switch = StrategySpec(\"regime_switch\", _regime_switch)\n",
        "\n",
        "# Estratégias usadas no run principal (tabela/figuras)\n",
        "strategies = [\n",
        "    *base_strategies,\n",
        "    cvar_constraint,\n",
        "    cvar_objective,\n",
        "    build_mean_cvar_strategy(spec_target, diagnostics=diag_target),\n",
        "    build_mean_cvar_strategy(spec_limit, diagnostics=diag_limit),\n",
        "    regime_switch,\n",
        "]\n",
        "\n",
        "[s.name for s in strategies]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Resultado principal (Tabela do artigo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "oos = compare_baselines(\n",
        "    returns,\n",
        "    strategies=strategies,\n",
        "    train_window=TRAIN_WINDOW,\n",
        "    test_window=TEST_WINDOW,\n",
        "    purge_window=PURGE_WINDOW,\n",
        "    embargo_window=EMBARGO_WINDOW,\n",
        "    costs_bps=COSTS_BPS,\n",
        "    max_position=MAX_POSITION,\n",
        "    bootstrap_iterations=BOOTSTRAP_ITERATIONS,\n",
        "    confidence=CONFIDENCE,\n",
        "    block_size=BLOCK_SIZE,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "\n",
        "metrics = oos.metrics.copy()\n",
        "\n",
        "# Transformações úteis para paper\n",
        "metrics[\"cvar_loss_95_annual\"] = -metrics[\"cvar_95_annual\"].astype(float)\n",
        "metrics[\"max_drawdown_abs\"] = metrics[\"max_drawdown\"].abs().replace(0.0, np.nan)\n",
        "metrics[\"cvar_95_annual_abs\"] = metrics[\"cvar_95_annual\"].abs().replace(0.0, np.nan)\n",
        "metrics[\"calmar\"] = metrics[\"annualized_return\"] / metrics[\"max_drawdown_abs\"]\n",
        "metrics[\"return_over_cvar\"] = metrics[\"annualized_return\"] / metrics[\"cvar_95_annual_abs\"]\n",
        "\n",
        "years = len(oos.returns) / 252.0\n",
        "metrics[\"cost_bps_per_year\"] = np.where(\n",
        "    years > 0,\n",
        "    metrics[\"total_cost\"].astype(float) / years * 10_000.0,\n",
        "    np.nan,\n",
        ")\n",
        "rebalances_per_year = 252.0 / TEST_WINDOW\n",
        "metrics[\"turnover_per_year\"] = metrics[\"avg_turnover\"].astype(float) * rebalances_per_year\n",
        "\n",
        "table_main = metrics[[\n",
        "    \"annualized_return\",\n",
        "    \"volatility\",\n",
        "    \"sharpe\",\n",
        "    \"cvar_loss_95_annual\",\n",
        "    \"max_drawdown\",\n",
        "    \"turnover_per_year\",\n",
        "    \"cost_bps_per_year\",\n",
        "    \"calmar\",\n",
        "    \"return_over_cvar\",\n",
        "    \"sharpe_ci_low\",\n",
        "    \"sharpe_ci_high\",\n",
        "]].copy()\n",
        "\n",
        "table_main = table_main.sort_values([\"return_over_cvar\", \"calmar\"], ascending=False)\n",
        "table_main\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Versão \"paper-ready\" (formatação)\n",
        "table_paper = table_main.copy()\n",
        "\n",
        "fmt_pct = lambda x: f\"{x*100:,.2f}%\" if pd.notna(x) else \"-\"\n",
        "fmt_num = lambda x: f\"{x:,.2f}\" if pd.notna(x) else \"-\"\n",
        "fmt_bps = lambda x: f\"{x:,.1f}\" if pd.notna(x) else \"-\"\n",
        "\n",
        "table_paper[\"annualized_return\"] = table_paper[\"annualized_return\"].map(fmt_pct)\n",
        "table_paper[\"volatility\"] = table_paper[\"volatility\"].map(fmt_pct)\n",
        "table_paper[\"cvar_loss_95_annual\"] = table_paper[\"cvar_loss_95_annual\"].map(fmt_pct)\n",
        "table_paper[\"max_drawdown\"] = table_paper[\"max_drawdown\"].map(fmt_pct)\n",
        "table_paper[\"turnover_per_year\"] = table_paper[\"turnover_per_year\"].map(fmt_num)\n",
        "table_paper[\"cost_bps_per_year\"] = table_paper[\"cost_bps_per_year\"].map(fmt_bps)\n",
        "table_paper[\"sharpe\"] = table_paper[\"sharpe\"].map(fmt_num)\n",
        "table_paper[\"calmar\"] = table_paper[\"calmar\"].map(fmt_num)\n",
        "table_paper[\"return_over_cvar\"] = table_paper[\"return_over_cvar\"].map(fmt_num)\n",
        "table_paper[\"sharpe_ci_low\"] = table_paper[\"sharpe_ci_low\"].map(fmt_num)\n",
        "table_paper[\"sharpe_ci_high\"] = table_paper[\"sharpe_ci_high\"].map(fmt_num)\n",
        "\n",
        "table_paper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tabela em LaTeX (cole direto no paper)\n",
        "latex_cols = {\n",
        "    \"annualized_return\": \"Ret (a.a.)\",\n",
        "    \"volatility\": \"Vol (a.a.)\",\n",
        "    \"sharpe\": \"Sharpe\",\n",
        "    \"cvar_loss_95_annual\": \"CVaR 95\\\\% (a.a., perda)\",\n",
        "    \"max_drawdown\": \"MaxDD\",\n",
        "    \"turnover_per_year\": \"Turnover/ano\",\n",
        "    \"cost_bps_per_year\": \"Custo (bps/ano)\",\n",
        "    \"calmar\": \"Calmar\",\n",
        "    \"return_over_cvar\": \"Ret/CVaR\",\n",
        "}\n",
        "\n",
        "table_paper[list(latex_cols.keys())].rename(columns=latex_cols).to_latex(\n",
        "    escape=False,\n",
        "    index=True,\n",
        "    caption=\"OOS (walk-forward): métricas principais.\",\n",
        "    label=\"tab:oos_main\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1) Critério de “vitória econômica” (do PDF)\n",
        "\n",
        "Regra prática proposta:\n",
        "- se a variante mean-CVaR tiver retorno absoluto menor, mas **Calmar ≥ 1.5×** ou **Ret/CVaR ≥ 1.5×** vs baseline, considerar “vitória econômica”.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "candidates = [name for name in metrics.index if name.startswith(\"mean_cvar\") or name == \"regime_switch\"]\n",
        "baselines = [name for name in metrics.index if name in {\"shrunk_mv\", \"equal_weight\", \"risk_parity\"}]\n",
        "\n",
        "rows: list[dict[str, Any]] = []\n",
        "for cand in candidates:\n",
        "    for base in baselines:\n",
        "        calmar_ratio = float(metrics.loc[cand, \"calmar\"] / metrics.loc[base, \"calmar\"]) if metrics.loc[base, \"calmar\"] else np.nan\n",
        "        roc_ratio = float(metrics.loc[cand, \"return_over_cvar\"] / metrics.loc[base, \"return_over_cvar\"]) if metrics.loc[base, \"return_over_cvar\"] else np.nan\n",
        "        ret_diff = float(metrics.loc[cand, \"annualized_return\"] - metrics.loc[base, \"annualized_return\"])\n",
        "        rows.append(\n",
        "            {\n",
        "                \"candidate\": cand,\n",
        "                \"baseline\": base,\n",
        "                \"ret_diff\": ret_diff,\n",
        "                \"calmar_ratio\": calmar_ratio,\n",
        "                \"ret_over_cvar_ratio\": roc_ratio,\n",
        "                \"passes_1.5x\": (calmar_ratio >= 1.5) or (roc_ratio >= 1.5),\n",
        "            }\n",
        "        )\n",
        "\n",
        "victory = pd.DataFrame(rows).sort_values([\"passes_1.5x\", \"ret_over_cvar_ratio\"], ascending=False)\n",
        "victory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2) Regime-switching: frequência e sinal\n",
        "\n",
        "O paper precisa mostrar **quanto tempo** o sistema fica em regime de estresse e qual o sinal usado (VIX ou proxy interno).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regime_df = pd.DataFrame(regime_log)\n",
        "if not regime_df.empty and \"regime_switch\" in oos.weights:\n",
        "    dates = [ts for ts, _ in oos.weights[\"regime_switch\"]]\n",
        "    regime_df[\"rebalance_date\"] = pd.to_datetime(dates[: len(regime_df)])\n",
        "    regime_df[\"rebalance_date\"] = regime_df[\"rebalance_date\"].dt.tz_localize(None)\n",
        "    regime_df = regime_df.sort_values(\"rebalance_date\")\n",
        "\n",
        "regime_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if regime_df.empty:\n",
        "    print(\"Regime log vazio: rode o bloco principal antes.\")\n",
        "else:\n",
        "    summary_regime = {\n",
        "        \"n_windows\": int(len(regime_df)),\n",
        "        \"stressed_rate\": float(regime_df[\"stressed\"].mean()),\n",
        "        \"signal\": str(regime_df[\"signal\"].iloc[0]) if \"signal\" in regime_df.columns else \"unknown\",\n",
        "        \"signal_value_min\": float(regime_df[\"signal_value\"].min()),\n",
        "        \"signal_value_p95\": float(regime_df[\"signal_value\"].quantile(0.95)),\n",
        "        \"signal_value_max\": float(regime_df[\"signal_value\"].max()),\n",
        "    }\n",
        "    summary_regime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not regime_df.empty:\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(regime_df[\"rebalance_date\"], regime_df[\"signal_value\"], lw=1.8)\n",
        "\n",
        "    threshold = VIX_THRESHOLD if regime_df[\"signal\"].iloc[0] == \"vix\" else VOL_THRESHOLD\n",
        "    ax.axhline(threshold, color=\"red\", linestyle=\"--\", lw=1.2, label=\"threshold\")\n",
        "\n",
        "    stressed = regime_df[regime_df[\"stressed\"]]\n",
        "    ax.scatter(stressed[\"rebalance_date\"], stressed[\"signal_value\"], color=\"red\", s=30, label=\"stressed\")\n",
        "\n",
        "    ax.set_title(\"Sinal de regime no rebalance (proxy interno ou VIX)\")\n",
        "    ax.set_ylabel(\"signal_value\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3) Equity curve do regime-switch (com marcação de estresse)\n",
        "\n",
        "Sombreia as janelas onde o sinal classificou o regime como estresse (proxy interno ou VIX).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if regime_df.empty or \"regime_switch\" not in oos.returns.columns:\n",
        "    print(\"Sem dados para plotar regime_switch (rode o run principal antes).\")\n",
        "else:\n",
        "    nav = (1.0 + oos.returns).cumprod()\n",
        "    reg = regime_df.sort_values(\"rebalance_date\").reset_index(drop=True)\n",
        "\n",
        "    cols = [c for c in [\"regime_switch\", \"mean_cvar_constraint\", \"shrunk_mv\"] if c in nav.columns]\n",
        "    fig, ax = plt.subplots()\n",
        "    for c in cols:\n",
        "        highlight = c == \"regime_switch\"\n",
        "        ax.plot(\n",
        "            nav.index,\n",
        "            nav[c],\n",
        "            label=c,\n",
        "            lw=2.6 if highlight else 1.4,\n",
        "            alpha=1.0 if highlight else 0.75,\n",
        "        )\n",
        "\n",
        "    dates = reg[\"rebalance_date\"].tolist()\n",
        "    for i, row in reg.iterrows():\n",
        "        start = row[\"rebalance_date\"]\n",
        "        end = dates[i + 1] if i + 1 < len(dates) else nav.index.max()\n",
        "        if bool(row.get(\"stressed\", False)):\n",
        "            ax.axvspan(start, end, color=\"red\", alpha=0.08)\n",
        "\n",
        "    ax.set_title(\"Equity curve OOS: regime-switch (stress shading)\")\n",
        "    ax.set_ylabel(\"NAV\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Figura principal: trade-off retorno vs risco de cauda\n",
        "\n",
        "Para OR, a leitura usual é que o controle de cauda implica trade-off. A figura abaixo posiciona cada estratégia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_points = metrics.copy()\n",
        "plot_points[\"cvar_loss_95_annual\"] = -plot_points[\"cvar_95_annual\"].astype(float)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "for name, row in plot_points.iterrows():\n",
        "    ax.scatter(row[\"cvar_loss_95_annual\"], row[\"annualized_return\"], s=90)\n",
        "    ax.annotate(name, (row[\"cvar_loss_95_annual\"], row[\"annualized_return\"]), xytext=(5, 5), textcoords=\"offset points\")\n",
        "\n",
        "ax.set_xlabel(\"CVaR 95% anual (perda, +)\")\n",
        "ax.set_ylabel(\"Retorno anualizado\")\n",
        "ax.set_title(\"Trade-off: retorno vs risco de cauda (OOS)\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.1) Curvas de equity e drawdown (Figura do artigo)\n",
        "\n",
        "Curvas OOS (NAV) e drawdown underwater para leitura visual do trade-off.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nav = (1.0 + oos.returns).cumprod()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "for name in nav.columns:\n",
        "    highlight = name.startswith(\"mean_cvar\")\n",
        "    ax.plot(\n",
        "        nav.index,\n",
        "        nav[name],\n",
        "        label=name,\n",
        "        lw=2.6 if highlight else 1.2,\n",
        "        alpha=1.0 if highlight else 0.65,\n",
        "    )\n",
        "\n",
        "ax.set_title(\"Equity curve OOS (NAV, base=1)\")\n",
        "ax.set_ylabel(\"NAV\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend(ncol=2, fontsize=8)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drawdown = nav.div(nav.cummax()) - 1.0\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "for name in drawdown.columns:\n",
        "    highlight = name.startswith(\"mean_cvar\")\n",
        "    ax.plot(\n",
        "        drawdown.index,\n",
        "        drawdown[name],\n",
        "        label=name,\n",
        "        lw=2.6 if highlight else 1.2,\n",
        "        alpha=1.0 if highlight else 0.65,\n",
        "    )\n",
        "\n",
        "ax.set_title(\"Drawdown OOS (underwater)\")\n",
        "ax.set_ylabel(\"drawdown\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend(ncol=2, fontsize=8)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.2) Turnover e custos (Figura do artigo)\n",
        "\n",
        "Distribuição de turnover por rebalance e custo implícito (em bps) usando `costs_bps`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "turnover_df = pd.DataFrame({name: pd.Series(values) for name, values in oos.turnovers.items()})\n",
        "cost_bps_df = turnover_df * COSTS_BPS\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "turnover_df.boxplot(ax=axes[0], rot=25)\n",
        "axes[0].set_title(\"Turnover one-way por rebalance\")\n",
        "axes[0].set_ylabel(\"turnover\")\n",
        "axes[0].grid(True, axis=\"y\", alpha=0.3)\n",
        "\n",
        "cost_bps_df.boxplot(ax=axes[1], rot=25)\n",
        "axes[1].set_title(\"Custo (bps) por rebalance\")\n",
        "axes[1].set_ylabel(\"bps\")\n",
        "axes[1].grid(True, axis=\"y\", alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.3) Estabilidade de pesos (evidência operacional)\n",
        "\n",
        "Além de turnover, é útil reportar estabilidade/complexidade da solução:\n",
        "- **N_eff** (número efetivo de ativos): 1/∑w²\n",
        "- **Max weight** (concentração)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _weight_stats(w: pd.Series) -> dict[str, float]:\n",
        "    weights = w.astype(float).fillna(0.0).clip(lower=0.0)\n",
        "    total = float(weights.sum())\n",
        "    if total > 0:\n",
        "        weights = weights / total\n",
        "    hhi = float((weights**2).sum())\n",
        "    n_eff = (1.0 / hhi) if hhi > 0 else np.nan\n",
        "    max_w = float(weights.max()) if not weights.empty else np.nan\n",
        "    n_active = float((weights > 1e-6).sum())\n",
        "    return {\n",
        "        \"n_active\": n_active,\n",
        "        \"n_eff\": float(n_eff),\n",
        "        \"max_weight\": max_w,\n",
        "    }\n",
        "\n",
        "\n",
        "records: list[dict[str, Any]] = []\n",
        "for strategy, snapshots in oos.weights.items():\n",
        "    for rebalance_date, weights in snapshots:\n",
        "        row = _weight_stats(weights)\n",
        "        row[\"strategy\"] = strategy\n",
        "        row[\"rebalance_date\"] = pd.to_datetime(rebalance_date).tz_localize(None)\n",
        "        records.append(row)\n",
        "\n",
        "weights_stats = pd.DataFrame(records)\n",
        "weights_stats.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "weights_stats.boxplot(column=\"n_eff\", by=\"strategy\", ax=axes[0], rot=25)\n",
        "axes[0].set_title(\"N_eff por rebalance\")\n",
        "axes[0].set_ylabel(\"N_eff\")\n",
        "axes[0].grid(True, axis=\"y\", alpha=0.3)\n",
        "\n",
        "weights_stats.boxplot(column=\"max_weight\", by=\"strategy\", ax=axes[1], rot=25)\n",
        "axes[1].set_title(\"Max weight por rebalance\")\n",
        "axes[1].set_ylabel(\"max weight\")\n",
        "axes[1].grid(True, axis=\"y\", alpha=0.3)\n",
        "\n",
        "plt.suptitle(\"\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Sensibilidade (τ do CVaR vs penalidade de turnover)\n",
        "\n",
        "Esta seção gera uma grade pequena *paper-friendly*.\n",
        "\n",
        "Se quiser rodar uma grade maior, aumente os grids abaixo (pode demorar)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_cvar_grid = [0.04, 0.05, 0.06, 0.07]\n",
        "turnover_penalty_grid = [0.0, 0.01, 0.02]\n",
        "\n",
        "records: list[dict[str, Any]] = []\n",
        "\n",
        "for max_cvar_loss, turnover_penalty in product(max_cvar_grid, turnover_penalty_grid):\n",
        "    tmp_diag: list[dict[str, Any]] = []\n",
        "    tmp_spec = CvarSpec(\n",
        "        name=\"mean_cvar_limit\",\n",
        "        alpha=0.95,\n",
        "        risk_aversion=1.5,\n",
        "        max_position=MAX_POSITION,\n",
        "        turnover_penalty=float(turnover_penalty),\n",
        "        turnover_cap=0.20,\n",
        "        target_return=None,\n",
        "        max_cvar_loss=float(max_cvar_loss),\n",
        "        solver=\"CLARABEL\",\n",
        "    )\n",
        "    spec = build_mean_cvar_strategy(tmp_spec, diagnostics=tmp_diag)\n",
        "\n",
        "    run = compare_baselines(\n",
        "        returns,\n",
        "        strategies=[*base_strategies, spec],\n",
        "        train_window=TRAIN_WINDOW,\n",
        "        test_window=TEST_WINDOW,\n",
        "        purge_window=PURGE_WINDOW,\n",
        "        embargo_window=EMBARGO_WINDOW,\n",
        "        costs_bps=COSTS_BPS,\n",
        "        max_position=MAX_POSITION,\n",
        "        bootstrap_iterations=0,\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "\n",
        "    m = run.metrics.loc[\"mean_cvar_limit\"].to_dict()\n",
        "    m[\"max_cvar_loss\"] = float(max_cvar_loss)\n",
        "    m[\"turnover_penalty\"] = float(turnover_penalty)\n",
        "    m[\"cvar_loss_95_annual\"] = -float(m.get(\"cvar_95_annual\", 0.0))\n",
        "    m[\"max_drawdown_abs\"] = abs(float(m.get(\"max_drawdown\", 0.0)))\n",
        "    denom = abs(float(m.get(\"cvar_95_annual\", 0.0)))\n",
        "    m[\"return_over_cvar\"] = (float(m.get(\"annualized_return\", 0.0)) / denom) if denom else np.nan\n",
        "\n",
        "    diag_df = pd.DataFrame(tmp_diag)\n",
        "    m[\"solver_opt_rate\"] = float((diag_df.get(\"status\") == \"optimal\").mean()) if not diag_df.empty else np.nan\n",
        "    m[\"solver_runtime_mean\"] = float(diag_df.get(\"runtime\", pd.Series(dtype=float)).mean()) if not diag_df.empty else np.nan\n",
        "\n",
        "    records.append(m)\n",
        "\n",
        "grid = pd.DataFrame(records)\n",
        "grid = grid.sort_values([\"return_over_cvar\", \"annualized_return\"], ascending=False)\n",
        "grid[[\n",
        "    \"max_cvar_loss\",\n",
        "    \"turnover_penalty\",\n",
        "    \"annualized_return\",\n",
        "    \"sharpe\",\n",
        "    \"cvar_95_annual\",\n",
        "    \"max_drawdown\",\n",
        "    \"avg_turnover\",\n",
        "    \"return_over_cvar\",\n",
        "    \"solver_opt_rate\",\n",
        "    \"solver_runtime_mean\",\n",
        "]].head(12)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "grid_plot = grid.copy()\n",
        "grid_plot[\"cvar_loss_95_annual\"] = -grid_plot[\"cvar_95_annual\"].astype(float)\n",
        "\n",
        "for penalty in sorted(grid_plot[\"turnover_penalty\"].unique()):\n",
        "    subset = grid_plot[grid_plot[\"turnover_penalty\"] == penalty]\n",
        "    ax.plot(\n",
        "        subset[\"cvar_loss_95_annual\"],\n",
        "        subset[\"annualized_return\"],\n",
        "        marker=\"o\",\n",
        "        linestyle=\"-\",\n",
        "        label=f\"turnover_penalty={penalty}\",\n",
        "        alpha=0.9,\n",
        "    )\n",
        "\n",
        "ax.set_xlabel(\"CVaR 95% anual (perda, +)\")\n",
        "ax.set_ylabel(\"Retorno anualizado\")\n",
        "ax.set_title(\"Sensibilidade: τ (CVaR) × penalidade de turnover\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1) Tabelas pivô e heatmap (τ × penalidade)\n",
        "\n",
        "Centraliza, em formato de tabela/figura, como τ e η alteram retorno, CVaR e turnover.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pivot_ret = grid.pivot_table(\n",
        "    index=\"max_cvar_loss\", columns=\"turnover_penalty\", values=\"annualized_return\"\n",
        ").sort_index()\n",
        "pivot_turn = grid.pivot_table(\n",
        "    index=\"max_cvar_loss\", columns=\"turnover_penalty\", values=\"avg_turnover\"\n",
        ").sort_index()\n",
        "pivot_cvar_ann = (-grid.pivot_table(\n",
        "    index=\"max_cvar_loss\", columns=\"turnover_penalty\", values=\"cvar_95_annual\"\n",
        ")).sort_index()\n",
        "pivot_roc = grid.pivot_table(\n",
        "    index=\"max_cvar_loss\", columns=\"turnover_penalty\", values=\"return_over_cvar\"\n",
        ").sort_index()\n",
        "\n",
        "print(\"Retorno anualizado\")\n",
        "display(pivot_ret)\n",
        "print(\"CVaR 95% anual (perda, +)\")\n",
        "display(pivot_cvar_ann)\n",
        "print(\"Turnover médio por rebalance\")\n",
        "display(pivot_turn)\n",
        "print(\"Ret/CVaR\")\n",
        "display(pivot_roc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "im = ax.imshow(pivot_roc.to_numpy(dtype=float), aspect=\"auto\", origin=\"lower\")\n",
        "\n",
        "ax.set_xticks(range(len(pivot_roc.columns)))\n",
        "ax.set_xticklabels([str(c) for c in pivot_roc.columns])\n",
        "ax.set_yticks(range(len(pivot_roc.index)))\n",
        "ax.set_yticklabels([str(i) for i in pivot_roc.index])\n",
        "\n",
        "ax.set_xlabel(\"turnover_penalty (η)\")\n",
        "ax.set_ylabel(\"max_cvar_loss (τ, diário)\")\n",
        "ax.set_title(\"Heatmap: Ret/CVaR (maior é melhor)\")\n",
        "fig.colorbar(im, ax=ax)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "for penalty in sorted(grid[\"turnover_penalty\"].unique()):\n",
        "    subset = grid[grid[\"turnover_penalty\"] == penalty].sort_values(\"max_cvar_loss\")\n",
        "    ax.plot(\n",
        "        subset[\"max_cvar_loss\"],\n",
        "        subset[\"avg_turnover\"],\n",
        "        marker=\"o\",\n",
        "        label=f\"η={penalty}\",\n",
        "    )\n",
        "\n",
        "ax.set_title(\"Sensibilidade de turnover ao limite de CVaR (τ)\")\n",
        "ax.set_xlabel(\"max_cvar_loss (τ, diário)\")\n",
        "ax.set_ylabel(\"avg_turnover (one-way)\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Estresse (Tabela por subperíodo)\n",
        "\n",
        "Para OR, é importante mostrar o comportamento em regimes de crise.\n",
        "Ajuste os períodos conforme o paper (e.g., COVID/2020, inflação/2022).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "periods = {\n",
        "    \"COVID-19 (2020Q1)\": (\"2020-02-19\", \"2020-04-30\"),\n",
        "    \"Inflation/Rate shock (2022)\": (\"2022-01-03\", \"2022-10-14\"),\n",
        "}\n",
        "\n",
        "stress = stress_test(\n",
        "    oos.returns,\n",
        "    periods,\n",
        "    bootstrap_iterations=0,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "\n",
        "if not stress.empty:\n",
        "    stress[\"cvar_loss_95_annual\"] = (-stress[\"cvar_95\"].astype(float)) * np.sqrt(252.0)\n",
        "    stress[\"max_drawdown\"] = stress[\"max_drawdown\"].astype(float)\n",
        "    stress = stress[[\n",
        "        \"period\",\n",
        "        \"strategy\",\n",
        "        \"annualized_return\",\n",
        "        \"volatility\",\n",
        "        \"sharpe\",\n",
        "        \"cvar_loss_95_annual\",\n",
        "        \"max_drawdown\",\n",
        "    ]].sort_values([\"period\", \"strategy\"])\n",
        "stress\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1) Turnover e custos por período (operabilidade)\n",
        "\n",
        "O PDF sugere reportar turnover/custos por regime (crise vs normal). Aqui usamos os mesmos subperíodos para resumir a operabilidade.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "turnover_by_date: dict[str, pd.Series] = {}\n",
        "for strategy, snapshots in oos.weights.items():\n",
        "    dates = [ts for ts, _ in snapshots]\n",
        "    values = oos.turnovers.get(strategy, [])\n",
        "    if not dates or len(values) != len(dates):\n",
        "        continue\n",
        "    turnover_by_date[strategy] = pd.Series(values, index=pd.to_datetime(dates)).sort_index()\n",
        "\n",
        "turnover_by_date_df = pd.DataFrame(turnover_by_date).sort_index()\n",
        "cost_bps_by_date_df = turnover_by_date_df * COSTS_BPS\n",
        "\n",
        "records: list[dict[str, Any]] = []\n",
        "for label, (start, end) in periods.items():\n",
        "    tw = turnover_by_date_df.loc[str(start) : str(end)]\n",
        "    cw = cost_bps_by_date_df.loc[str(start) : str(end)]\n",
        "    for strategy in tw.columns:\n",
        "        series = tw[strategy].dropna()\n",
        "        if series.empty:\n",
        "            continue\n",
        "        cost_series = cw[strategy].dropna()\n",
        "        records.append(\n",
        "            {\n",
        "                \"period\": label,\n",
        "                \"strategy\": strategy,\n",
        "                \"n_rebalances\": int(series.size),\n",
        "                \"turnover_mean\": float(series.mean()),\n",
        "                \"turnover_p95\": float(series.quantile(0.95)),\n",
        "                \"cost_bps_mean\": float(cost_series.mean()) if not cost_series.empty else np.nan,\n",
        "                \"cost_bps_p95\": float(cost_series.quantile(0.95)) if not cost_series.empty else np.nan,\n",
        "            }\n",
        "        )\n",
        "\n",
        "ops_by_period = pd.DataFrame(records).sort_values([\"period\", \"strategy\"]).reset_index(drop=True)\n",
        "ops_by_period\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Diagnóstico do solver (tabela + figura)\n",
        "\n",
        "Esta seção é um diferencial em OR: reporta estabilidade, status e tempo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diag_df_target = pd.DataFrame(diag_target)\n",
        "diag_df_limit = pd.DataFrame(diag_limit)\n",
        "diag_df_constraint = pd.DataFrame(diag_constraint)\n",
        "diag_df_objective = pd.DataFrame(diag_objective)\n",
        "\n",
        "def summarize_diag(df: pd.DataFrame, *, label: str) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return pd.DataFrame({\"label\": [label], \"n\": [0]})\n",
        "    status_counts = df[\"status\"].value_counts(dropna=False).to_dict() if \"status\" in df.columns else {}\n",
        "    optimal_rate = float((df.get(\"status\") == \"optimal\").mean()) if \"status\" in df.columns else float(\"nan\")\n",
        "    runtime = df.get(\"runtime\", pd.Series(dtype=float))\n",
        "    return pd.DataFrame(\n",
        "        {\n",
        "            \"label\": [label],\n",
        "            \"n_windows\": [int(len(df))],\n",
        "            \"optimal_rate\": [optimal_rate],\n",
        "            \"runtime_mean_s\": [float(runtime.mean()) if not runtime.empty else np.nan],\n",
        "            \"runtime_p95_s\": [float(runtime.quantile(0.95)) if not runtime.empty else np.nan],\n",
        "            \"status_counts\": [status_counts],\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "pd.concat(\n",
        "    [\n",
        "        summarize_diag(diag_df_constraint, label=\"mean_cvar_constraint\"),\n",
        "        summarize_diag(diag_df_objective, label=\"mean_cvar_objective\"),\n",
        "        summarize_diag(diag_df_target, label=\"mean_cvar_target\"),\n",
        "        summarize_diag(diag_df_limit, label=\"mean_cvar_limit\"),\n",
        "    ],\n",
        "    ignore_index=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.1) Aderência às restrições e taxa de binding (OR)\n",
        "\n",
        "Para o artigo em OR, é útil reportar quantas janelas respeitam as restrições (CVaR/turnover) e quando elas ficam ativas (binding).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _adherence(df: pd.DataFrame, *, label: str, tol: float = 1e-6) -> dict[str, Any]:\n",
        "    if df.empty:\n",
        "        return {\"label\": label, \"n_windows\": 0}\n",
        "\n",
        "    status = df.get(\"status\", pd.Series(dtype=str)).astype(str)\n",
        "    optimal = status.str.startswith(\"optimal\")\n",
        "\n",
        "    out: dict[str, Any] = {\n",
        "        \"label\": label,\n",
        "        \"n_windows\": int(len(df)),\n",
        "        \"optimal_rate\": float(optimal.mean()) if len(optimal) else np.nan,\n",
        "    }\n",
        "\n",
        "    if \"turnover_cap\" in df.columns and df[\"turnover_cap\"].notna().any() and \"turnover\" in df.columns:\n",
        "        cap = df[\"turnover_cap\"].astype(float)\n",
        "        val = df[\"turnover\"].astype(float)\n",
        "        mask = cap.notna() & val.notna()\n",
        "        out[\"turnover_within_cap_rate\"] = float((val[mask] <= cap[mask] + tol).mean()) if mask.any() else np.nan\n",
        "        out[\"turnover_binding_rate\"] = float((np.abs(val[mask] - cap[mask]) <= 1e-3).mean()) if mask.any() else np.nan\n",
        "    else:\n",
        "        out[\"turnover_within_cap_rate\"] = np.nan\n",
        "        out[\"turnover_binding_rate\"] = np.nan\n",
        "\n",
        "    if \"max_cvar_loss\" in df.columns and df[\"max_cvar_loss\"].notna().any() and \"cvar_loss\" in df.columns:\n",
        "        cap = df[\"max_cvar_loss\"].astype(float)\n",
        "        val = df[\"cvar_loss\"].astype(float)\n",
        "        mask = cap.notna() & val.notna()\n",
        "        out[\"cvar_within_cap_rate\"] = float((val[mask] <= cap[mask] + tol).mean()) if mask.any() else np.nan\n",
        "        out[\"cvar_binding_rate\"] = float((np.abs(val[mask] - cap[mask]) <= 1e-3).mean()) if mask.any() else np.nan\n",
        "    else:\n",
        "        out[\"cvar_within_cap_rate\"] = np.nan\n",
        "        out[\"cvar_binding_rate\"] = np.nan\n",
        "\n",
        "    runtime = df.get(\"runtime\", pd.Series(dtype=float))\n",
        "    out[\"runtime_mean_s\"] = float(runtime.mean()) if not runtime.empty else np.nan\n",
        "    out[\"runtime_p95_s\"] = float(runtime.quantile(0.95)) if not runtime.empty else np.nan\n",
        "    return out\n",
        "\n",
        "\n",
        "adherence = pd.DataFrame(\n",
        "    [\n",
        "        _adherence(diag_df_constraint, label=\"mean_cvar_constraint\"),\n",
        "        _adherence(diag_df_objective, label=\"mean_cvar_objective\"),\n",
        "        _adherence(diag_df_target, label=\"mean_cvar_target\"),\n",
        "        _adherence(diag_df_limit, label=\"mean_cvar_limit\"),\n",
        "    ]\n",
        ").set_index(\"label\")\n",
        "\n",
        "adherence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "for label, df in [\n",
        "    (\"mean_cvar_constraint\", diag_df_constraint),\n",
        "    (\"mean_cvar_objective\", diag_df_objective),\n",
        "    (\"mean_cvar_target\", diag_df_target),\n",
        "    (\"mean_cvar_limit\", diag_df_limit),\n",
        "]:\n",
        "    if not df.empty and \"runtime\" in df.columns:\n",
        "        ax.hist(df[\"runtime\"].dropna().values, bins=20, alpha=0.5, label=label)\n",
        "\n",
        "ax.set_title(\"Distribuição do tempo de solver (por janela)\")\n",
        "ax.set_xlabel(\"tempo (s)\")\n",
        "ax.set_ylabel(\"# janelas\")\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend(fontsize=8)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Reprodutibilidade (snapshot)\n",
        "\n",
        "Este bloco gera um JSON pequeno para copiar/colar no apêndice do paper.\n",
        "Ele é exibido na saída (não escreve em disco).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bundle = {\n",
        "    \"env\": env,\n",
        "    \"data\": summary,\n",
        "    \"experiment\": {\n",
        "        \"train_window\": TRAIN_WINDOW,\n",
        "        \"test_window\": TEST_WINDOW,\n",
        "        \"purge_window\": PURGE_WINDOW,\n",
        "        \"embargo_window\": EMBARGO_WINDOW,\n",
        "        \"costs_bps\": COSTS_BPS,\n",
        "        \"max_position\": MAX_POSITION,\n",
        "        \"strategies\": [s.name for s in strategies],\n",
        "        \"bootstrap_iterations\": BOOTSTRAP_ITERATIONS,\n",
        "        \"block_size\": BLOCK_SIZE,\n",
        "        \"random_state\": RANDOM_STATE,\n",
        "        \"cvar_convention\": \"optimizer models loss (+); evaluation reports tail returns (-), annualized via sqrt(252)\",\n",
        "    },\n",
        "}\n",
        "\n",
        "print(json.dumps(bundle, indent=2, sort_keys=True))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
