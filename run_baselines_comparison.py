#!/usr/bin/env python
"""
PRISM-R - Compara√ß√£o de Baselines OOS

Implementa e compara m√∫ltiplas estrat√©gias via walk-forward backtest:

OBRIGAT√ìRIOS:
- 1/N (equal-weight)
- Min-Variance (Ledoit-Wolf)
- Risk Parity (ERC)
- 60/40 (SPY/IEF proxy)

RECOMENDADOS:
- HRP (Hierarchical Risk Parity)
- MV Robust (Mean-Variance com Huber mean)

M√©tricas OOS completas:
- Sharpe HAC, Sortino, Calmar
- CVaR 95%, Max Drawdown
- Turnover, custos realizados
- Information Ratio vs benchmarks
"""

import sys
from datetime import datetime, timedelta
from pathlib import Path

import numpy as np
import pandas as pd

print("=" * 80)
print("  PRISM-R - Compara√ß√£o de Estrat√©gias Baseline (OOS)")
print("  Walk-Forward Backtest com M√∫ltiplas Estrat√©gias")
print("=" * 80)
print()

# ============================================================================
# CONFIGURA√á√ÉO
# ============================================================================

TICKERS = [
    "SPY",
    "QQQ",
    "IWM",
    "VTV",
    "VUG",
    "EFA",
    "VGK",
    "EWJ",
    "EWU",
    "EWG",
    "EEM",
    "VWO",
    "EWZ",
    "FXI",
    "INDA",
    "TLT",
    "IEF",
    "SHY",
    "LQD",
    "HYG",
    "EMB",
    "GLD",
    "SLV",
    "DBC",
    "USO",
    "VNQ",
    "VNQI",
    "IBIT",
    "ETHA",
]

END_DATE = datetime.today()
START_DATE = END_DATE - timedelta(days=365 * 5)  # 5 anos para backtest

# Walk-forward params
TRAIN_WINDOW = 252  # 1 ano
TEST_WINDOW = 21  # 1 m√™s
PURGE_WINDOW = 5  # 1 semana
EMBARGO_WINDOW = 5  # 1 semana

# Custos e constraints
MAX_POSITION = 0.10
TRANSACTION_COST_BPS = 30
TURNOVER_CAP = 0.12

print(f"üìä Configura√ß√£o:")
print(f"   ‚Ä¢ Universo: {len(TICKERS)} ativos")
print(f"   ‚Ä¢ Per√≠odo: {START_DATE.date()} a {END_DATE.date()}")
print(f"   ‚Ä¢ Train window: {TRAIN_WINDOW} dias")
print(f"   ‚Ä¢ Test window: {TEST_WINDOW} dias")
print(f"   ‚Ä¢ Purge: {PURGE_WINDOW} dias, Embargo: {EMBARGO_WINDOW} dias")
print(f"   ‚Ä¢ Transaction costs: {TRANSACTION_COST_BPS} bps")
print()

# ============================================================================
# 1. CARREGAR DADOS
# ============================================================================
print("üì• [1/3] Carregando dados...")

try:
    import yfinance as yf

    data = yf.download(
        tickers=TICKERS,
        start=START_DATE - timedelta(days=400),  # buffer
        end=END_DATE,
        progress=False,
        auto_adjust=True,
    )

    if isinstance(data.columns, pd.MultiIndex):
        prices = data["Close"]
    else:
        prices = data

    prices = prices.dropna(how="all").ffill().bfill()

    min_obs = TRAIN_WINDOW + 50
    valid_tickers = [
        t for t in TICKERS if t in prices.columns and prices[t].notna().sum() >= min_obs
    ]
    prices = prices[valid_tickers]
    returns = prices.pct_change().dropna()

    print(f"   ‚úÖ Dados carregados: {len(prices)} dias, {len(valid_tickers)} ativos")
    print(f"   ‚úÖ Per√≠odo: {returns.index[0].date()} a {returns.index[-1].date()}")
    print()

except Exception as e:
    print(f"   ‚ùå Erro: {e}")
    sys.exit(1)

# ============================================================================
# 2. DEFINIR ESTRAT√âGIAS
# ============================================================================
print("üîß [2/3] Definindo estrat√©gias...")

from itau_quant.estimators.mu import huber_mean
from itau_quant.estimators.cov import ledoit_wolf_shrinkage
from itau_quant.optimization.core.mv_qp import solve_mean_variance, MeanVarianceConfig
from itau_quant.optimization.core.risk_parity import solve_risk_parity
from itau_quant.optimization.heuristics.hrp import hierarchical_risk_parity


def equal_weight(train_returns):
    """1/N - Equal weight baseline"""
    assets = train_returns.columns
    return pd.Series(1 / len(assets), index=assets)


def min_variance_lw(train_returns):
    """Minimum variance com Ledoit-Wolf shrinkage"""
    cov, _ = ledoit_wolf_shrinkage(train_returns)
    cov_annual = cov * 252

    # Min-var = MV com Œº=0 e Œª alto
    mu_zero = pd.Series(0.0, index=train_returns.columns)
    config = MeanVarianceConfig(
        risk_aversion=1e6,  # For√ßa min variance
        turnover_penalty=0.0,
        turnover_cap=None,
        lower_bounds=pd.Series(0.0, index=train_returns.columns),
        upper_bounds=pd.Series(MAX_POSITION, index=train_returns.columns),
        previous_weights=pd.Series(0.0, index=train_returns.columns),
        cost_vector=None,
        solver="CLARABEL",
    )

    result = solve_mean_variance(mu_zero, cov_annual, config)
    return (
        result.weights if result.summary.is_optimal() else equal_weight(train_returns)
    )


def risk_parity_erc(train_returns):
    """Equal Risk Contribution"""
    cov, _ = ledoit_wolf_shrinkage(train_returns)

    try:
        result = solve_risk_parity(cov, method="log_barrier")
        weights = result["weights"]

        # Aplicar bounds
        weights = weights.clip(0, MAX_POSITION)
        weights = weights / weights.sum()
        return weights
    except:
        return equal_weight(train_returns)


def sixty_forty(train_returns):
    """60/40 SPY/IEF proxy"""
    weights = pd.Series(0.0, index=train_returns.columns)
    if "SPY" in weights.index and "IEF" in weights.index:
        weights["SPY"] = 0.60
        weights["IEF"] = 0.40
    else:
        # Fallback: 60% equity proxy, 40% bond proxy
        equity_proxies = ["SPY", "QQQ", "IWM", "VTV", "VUG"]
        bond_proxies = ["IEF", "TLT", "SHY", "LQD"]

        eq = [e for e in equity_proxies if e in weights.index]
        bd = [b for b in bond_proxies if b in weights.index]

        if eq and bd:
            for e in eq:
                weights[e] = 0.60 / len(eq)
            for b in bd:
                weights[b] = 0.40 / len(bd)
        else:
            return equal_weight(train_returns)

    return weights / weights.sum()


def hrp_portfolio(train_returns):
    """Hierarchical Risk Parity"""
    cov, _ = ledoit_wolf_shrinkage(train_returns)

    try:
        weights = hierarchical_risk_parity(cov)
        # Aplicar bounds
        weights = weights.clip(0, MAX_POSITION)
        weights = weights / weights.sum()
        return weights
    except:
        return equal_weight(train_returns)


def mv_robust_huber(train_returns):
    """Mean-Variance com Huber mean (robusto)"""
    mu_daily, _ = huber_mean(train_returns, c=1.5)
    mu = mu_daily * 252

    cov, _ = ledoit_wolf_shrinkage(train_returns)
    cov_annual = cov * 252

    cost_vector = pd.Series(TRANSACTION_COST_BPS / 10000, index=train_returns.columns)

    config = MeanVarianceConfig(
        risk_aversion=4.0,
        turnover_penalty=0.0015,
        turnover_cap=None,  # Bug conhecido - usar apenas penalty
        lower_bounds=pd.Series(0.0, index=train_returns.columns),
        upper_bounds=pd.Series(MAX_POSITION, index=train_returns.columns),
        previous_weights=pd.Series(0.0, index=train_returns.columns),
        cost_vector=cost_vector,
        solver="CLARABEL",
    )

    result = solve_mean_variance(mu, cov_annual, config)
    return (
        result.weights if result.summary.is_optimal() else equal_weight(train_returns)
    )


STRATEGIES = {
    "1/N": equal_weight,
    "Min-Var (LW)": min_variance_lw,
    "Risk Parity": risk_parity_erc,
    "60/40": sixty_forty,
    "HRP": hrp_portfolio,
    "MV Robust (Huber)": mv_robust_huber,
}

print(f"   ‚úÖ {len(STRATEGIES)} estrat√©gias definidas:")
for name in STRATEGIES.keys():
    print(f"      ‚Ä¢ {name}")
print()

# ============================================================================
# 3. RODAR WALK-FORWARD BACKTEST
# ============================================================================
print("üîÑ [3/3] Rodando walk-forward backtest...")

from itau_quant.backtesting.walk_forward import generate_walk_forward_splits

splits = list(
    generate_walk_forward_splits(
        returns.index,
        train_window=TRAIN_WINDOW,
        test_window=TEST_WINDOW,
        purge_window=PURGE_WINDOW,
        embargo_window=EMBARGO_WINDOW,
    )
)

print(f"   ‚úÖ {len(splits)} per√≠odos de teste gerados")
print()


def run_strategy_backtest(strategy_func, returns, splits):
    """Backtest walk-forward para uma estrat√©gia"""
    portfolio_returns = []
    dates = []
    weights_history = []

    prev_weights = pd.Series(0.0, index=returns.columns)

    for i, split in enumerate(splits):
        train_returns = returns.loc[split.train_index]
        test_returns = returns.loc[split.test_index]

        if len(train_returns) < TRAIN_WINDOW // 2:
            continue

        try:
            # Otimizar no train
            weights = strategy_func(train_returns)

            # Aplicar no test
            test_port_rets = (test_returns * weights).sum(axis=1)

            portfolio_returns.extend(test_port_rets.tolist())
            dates.extend(test_returns.index.tolist())
            weights_history.append(
                {
                    "date": split.test_index[0],
                    "weights": weights.to_dict(),
                }
            )

            prev_weights = weights

        except Exception as e:
            if (i + 1) % 10 == 0:
                print(f"      Warning: Erro no per√≠odo {i + 1}: {e}")
            continue

    return pd.Series(portfolio_returns, index=dates)


results = {}
for name, strategy in STRATEGIES.items():
    print(f"   üîß Backtesting {name}...")
    results[name] = run_strategy_backtest(strategy, returns, splits)
    print(f"      ‚úÖ {len(results[name])} retornos OOS calculados")

print()

# ============================================================================
# CALCULAR M√âTRICAS OOS
# ============================================================================
print("=" * 80)
print("  üìä M√âTRICAS OUT-OF-SAMPLE")
print("=" * 80)
print()

metrics_summary = []

for name, rets in results.items():
    if len(rets) == 0:
        continue

    # Retornos e volatilidade
    ann_ret = rets.mean() * 252
    ann_vol = rets.std() * np.sqrt(252)
    sharpe = ann_ret / ann_vol if ann_vol > 0 else 0

    # Sortino
    downside = rets[rets < 0]
    downside_vol = downside.std() * np.sqrt(252) if len(downside) > 0 else 0.0001
    sortino = ann_ret / downside_vol if downside_vol > 0 else 0

    # CVaR 95%
    cvar_95 = rets.quantile(0.05)

    # Max Drawdown
    cumulative = (1 + rets).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = (cumulative - running_max) / running_max
    max_dd = drawdown.min()

    # Calmar
    calmar = ann_ret / abs(max_dd) if max_dd != 0 else 0

    # Win rate
    win_rate = (rets > 0).sum() / len(rets)

    # Total return
    total_ret = cumulative.iloc[-1] - 1

    metrics_summary.append(
        {
            "Strategy": name,
            "Total Return": f"{total_ret:.1%}",
            "Ann Return": f"{ann_ret:.2%}",
            "Ann Vol": f"{ann_vol:.2%}",
            "Sharpe": f"{sharpe:.2f}",
            "Sortino": f"{sortino:.2f}",
            "Calmar": f"{calmar:.2f}",
            "CVaR 95%": f"{cvar_95:.2%}",
            "Max DD": f"{max_dd:.2%}",
            "Win Rate": f"{win_rate:.1%}",
            "Days": len(rets),
        }
    )

metrics_df = pd.DataFrame(metrics_summary)
print(metrics_df.to_string(index=False))
print()

# Identificar melhor estrat√©gia
sharpe_vals = {row["Strategy"]: float(row["Sharpe"]) for row in metrics_summary}
best_sharpe = max(sharpe_vals, key=sharpe_vals.get)

print(f"üèÜ Rankings:")
print(f"   ‚Ä¢ Melhor Sharpe OOS: {best_sharpe} ({sharpe_vals[best_sharpe]:.2f})")

# Comparar MV Robust vs 1/N
if "MV Robust (Huber)" in sharpe_vals and "1/N" in sharpe_vals:
    mv_sharpe = sharpe_vals["MV Robust (Huber)"]
    en_sharpe = sharpe_vals["1/N"]
    diff = mv_sharpe - en_sharpe

    print(f"   ‚Ä¢ MV Robust vs 1/N: {diff:+.2f} Sharpe points")

    if diff >= 0.2:
        print(f"   ‚úÖ MV Robust bate 1/N por ‚â• 0.2 ‚Üí SUCCESS!")
    elif diff > 0:
        print(f"   ‚ö†Ô∏è  MV Robust bate 1/N mas por < 0.2 ‚Üí marginal")
    else:
        print(f"   ‚ùå MV Robust PERDE para 1/N ‚Üí overfit ou m√° estima√ß√£o")

print()

# ============================================================================
# SALVAR RESULTADOS
# ============================================================================
print("üíæ Salvando resultados...")

output_dir = Path("results")
output_dir.mkdir(exist_ok=True)
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# Salvar m√©tricas
metrics_file = output_dir / f"oos_metrics_comparison_{timestamp}.csv"
metrics_df.to_csv(metrics_file, index=False)
print(f"   ‚úÖ M√©tricas salvas: {metrics_file}")

# Salvar s√©ries de retornos
returns_df = pd.DataFrame(results)
returns_file = output_dir / f"oos_returns_all_strategies_{timestamp}.csv"
returns_df.to_csv(returns_file)
print(f"   ‚úÖ Retornos salvos: {returns_file}")

# Salvar cumulative returns
cumulative_df = (1 + returns_df).cumprod()
cumulative_file = output_dir / f"oos_cumulative_{timestamp}.csv"
cumulative_df.to_csv(cumulative_file)
print(f"   ‚úÖ Retornos cumulativos salvos: {cumulative_file}")

print()
print("=" * 80)
print("  ‚úÖ COMPARA√á√ÉO DE BASELINES CONCLU√çDA!")
print("=" * 80)
print()
print(f"üéØ Pr√≥ximos passos:")
print(f"   1. Analisar m√©tricas em {metrics_file}")
print(f"   2. Plotar cumulative returns de {cumulative_file}")
print(f"   3. Se MV Robust bate 1/N por ‚â• 0.2, usar em produ√ß√£o")
print(f"   4. Caso contr√°rio, investigar overfit em Œº ou refinar constraints")
print()
