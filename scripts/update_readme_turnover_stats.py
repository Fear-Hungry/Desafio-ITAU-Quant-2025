#!/usr/bin/env python3
"""
Update README table 5.1 with Turnover (mediana) and (p95) pulled from
per-window distribution stats CSVs.

What this script does:
- Loads turnover distribution stats for baselines from:
    results/oos_canonical/turnover_dist_stats.csv
  (generated by scripts/baselines/export_per_window_turnover.py)
- Computes PRISM-R turnover mediana/p95 from:
    reports/walkforward/per_window_results.csv
  filtered to the canonical OOS period defined in:
    configs/oos_period.yaml
  (falls back to per_window_results.csv when trades.csv unavailable)
- Locates the Table 5.1 in README.md and fills the columns
  "Turnover (mediana)" and "Turnover (p95)" for each strategy that has data.

Usage:
    poetry run python scripts/update_readme_turnover_stats.py \
        --readme README.md \
        --summary results/oos_canonical/turnover_dist_stats.csv \
        --per-window-prism reports/walkforward/per_window_results.csv \
        --oos-config configs/oos_period.yaml \
        [--force-overwrite]

Notes:
- Formatting of turnover values follows scientific notation with 2 decimals (e.g., 1.92e-02),
  matching the style used in the README for "Turnover (médio ...)" column.
- Only the two turnover distribution columns are modified; other columns are preserved verbatim.
"""

from __future__ import annotations

import argparse
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd
import yaml


REPO_ROOT = Path(__file__).resolve().parents[1]
DEFAULT_README = REPO_ROOT / "README.md"
DEFAULT_SUMMARY = REPO_ROOT / "results" / "oos_canonical" / "turnover_dist_stats.csv"
DEFAULT_PER_WINDOW_PRISM = REPO_ROOT / "reports" / "walkforward" / "per_window_results.csv"
DEFAULT_PRISM_TRADES = REPO_ROOT / "reports" / "walkforward" / "trades.csv"
DEFAULT_OOS_CONFIG = REPO_ROOT / "configs" / "oos_period.yaml"


@dataclass
class OOSPeriod:
    start: pd.Timestamp
    end: pd.Timestamp


def load_oos_period(oos_config_path: Path) -> OOSPeriod:
    with open(oos_config_path, "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)
    oos = cfg.get("oos_evaluation", {})
    start = pd.to_datetime(oos.get("start_date"))
    end = pd.to_datetime(oos.get("end_date"))
    if pd.isna(start) or pd.isna(end):
        raise ValueError(f"Invalid OOS period in {oos_config_path}")
    return OOSPeriod(start=start, end=end)


def fmt_sci(x: float) -> str:
    """Format float in scientific notation with 2 decimals (e.g., 1.92e-02)."""
    return f"{x:.2e}"


def load_baseline_summary(summary_csv: Path) -> Dict[str, Tuple[float, float]]:
    """
    Load turnover distribution summary for baselines.
    Expected columns: strategy, turnover_median, turnover_p95
    Returns mapping {strategy_key: (median, p95)}.
    """
    if not summary_csv.exists():
        print(f"[DEBUG] Baseline summary CSV not found: {summary_csv}")
        return {}

    df = pd.read_csv(summary_csv)
    print(f"[DEBUG] Loaded baseline summary: {len(df)} rows from {summary_csv}")
    out: Dict[str, Tuple[float, float]] = {}
    for _, row in df.iterrows():
        key = str(row["strategy"]).strip()
        med = float(row["turnover_median"])
        p95 = float(row["turnover_p95"])
        out[key] = (med, p95)
    print(f"[DEBUG] Baseline strategies in summary: {sorted(list(out.keys()))}")
    return out


def compute_prism_turnover_from_trades(
    trades_csv: Path, oos: OOSPeriod
) -> Optional[Tuple[float, float]]:
    """
    Compute PRISM turnover (median, p95) directly from trade-level exports.
    Expected columns: date, turnover
    """
    if not trades_csv.exists():
        print(f"[DEBUG] PRISM trades CSV not found: {trades_csv}")
        return None
    df = pd.read_csv(trades_csv)
    if "date" not in df.columns or "turnover" not in df.columns:
        print(f"[DEBUG] Trades CSV missing required columns. Found: {list(df.columns)}")
        return None
    df["date"] = pd.to_datetime(df["date"])
    mask = (df["date"] >= oos.start) & (df["date"] <= oos.end)
    filtered = df.loc[mask, "turnover"].astype(float)
    if filtered.empty:
        print(f"[DEBUG] Trades CSV rows after OOS filter: 0")
        return None
    med = float(filtered.median())
    p95 = float(filtered.quantile(0.95))
    print(
        f"[DEBUG] PRISM turnover (trades) med={med:.6e}, p95={p95:.6e} "
        f"(rows_oos={len(filtered)})"
    )
    return med, p95


def compute_prism_turnover_from_windows(
    per_window_csv: Path, oos: OOSPeriod
) -> Optional[Tuple[float, float]]:
    """
    Compute PRISM-R turnover (mediana, p95) from per-window CSV filtered to OOS period.
    Expected columns: Window End, Turnover
    """
    if not per_window_csv.exists():
        print(f"[DEBUG] PRISM per-window CSV not found: {per_window_csv}")
        return None
    df = pd.read_csv(per_window_csv)
    # Normalize columns
    end_col = "Window End" if "Window End" in df.columns else "date"
    turn_col = "Turnover" if "Turnover" in df.columns else "turnover"
    if end_col not in df.columns or turn_col not in df.columns:
        print(f"[DEBUG] PRISM per-window CSV missing required columns. Found: {list(df.columns)}")
        return None
    df[end_col] = pd.to_datetime(df[end_col])
    # Filter to OOS
    mask = (df[end_col] >= oos.start) & (df[end_col] <= oos.end)
    dff = df.loc[mask].copy()
    if dff.empty:
        print(f"[DEBUG] PRISM per-window rows after OOS filter: 0")
        return None
    med = float(pd.to_numeric(dff[turn_col], errors="coerce").median())
    p95 = float(pd.to_numeric(dff[turn_col], errors="coerce").quantile(0.95))
    print(f"[DEBUG] PRISM per-window CSV: {per_window_csv} (rows_total={len(df)}, rows_oos={len(dff)})")
    print(f"[DEBUG] PRISM turnover med={med:.6e}, p95={p95:.6e}")
    return med, p95


def find_table_block(lines: List[str]) -> Tuple[int, int, List[str]]:
    """
    Locate the Table 5.1 block by detecting the header row that contains the
    Turnover columns, and return (start_idx, end_idx, table_lines).
    The table ends before the first non-table line after the separator.
    """
    print(f"[DEBUG] Scanning README for table header (total lines={len(lines)})")
    start = -1
    for i, ln in enumerate(lines):
        s = ln.strip()
        if not s.startswith("| Estratégia"):
            continue
        # Accept multiple header variants, e.g. "Turnover mediano (‖Δw‖₁)" or "Turnover (mediana)"
        has_turnover = ("Turnover" in s)
        has_med = ("mediana" in s) or ("mediano" in s) or ("median" in s)
        has_p95 = ("p95" in s)
        if has_turnover and has_med and has_p95:
            start = i
            break
    if start == -1:
        print("[DEBUG] Table 5.1 header not found with required columns.")
        raise RuntimeError(
            "Could not find the Table 5.1 header with Turnover columns (mediana/mediano) and p95"
        )
    print(f"[DEBUG] Found table header at line {start}: {lines[start]}")
    # Find table end: first line after start that doesn't start with '|' (skip code fences)
    end = start + 1
    while end < len(lines):
        s = lines[end].strip()
        if not s.startswith("|"):
            break
        end += 1
    print(f"[DEBUG] Table block lines: start={start}, end={end}, length={end-start}")
    # The table is lines[start:end]
    return start, end, lines[start:end]


def parse_table(table_lines: List[str]) -> Tuple[List[str], List[List[str]]]:
    """
    Parse markdown table into header columns and rows of values.
    Keeps raw strings; trimming spaces around each cell.
    """
    if len(table_lines) < 2:
        raise ValueError("Table too short to parse")

    header = [c.strip() for c in table_lines[0].strip().strip("|").split("|")]
    print(f"[DEBUG] Parsed table header columns (n={len(header)}): {header}")
    # Skip separator (assumed at line 1)
    rows: List[List[str]] = []
    for ln in table_lines[2:]:
        if not ln.strip().startswith("|"):
            continue
        parts = [c.strip() for c in ln.strip().strip("|").split("|")]
        # Pad/truncate to header length to be safe
        if len(parts) < len(header):
            parts += [""] * (len(header) - len(parts))
        elif len(parts) > len(header):
            parts = parts[: len(header)]
        rows.append(parts)
    print(f"[DEBUG] Parsed {len(rows)} data rows from table")
    return header, rows


def rebuild_table(header: List[str], rows: List[List[str]], original_lines: List[str]) -> List[str]:
    """
    Rebuild markdown table preserving the original separator line formatting.
    """
    # Header
    out = []
    out.append("| " + " | ".join(header) + " |")
    # Keep original separator line if available, else synthesize
    if len(original_lines) >= 2 and original_lines[1].strip().startswith("|"):
        out.append(original_lines[1].rstrip("\n"))
    else:
        sep = ["---"] * len(header)
        out.append("| " + " | ".join(sep) + " |")
    # Rows
    for r in rows:
        out.append("| " + " | ".join(r) + " |")
    return out


def update_readme_table(
    readme_path: Path,
    summary_map: Dict[str, Tuple[float, float]],
    prism_stats: Optional[Tuple[float, float]],
    force_overwrite: bool,
) -> int:
    """
    Update the README table in place. Returns number of rows updated.
    """
    text = readme_path.read_text(encoding="utf-8").splitlines(keepends=False)
    start, end, tbl = find_table_block(text)
    header, rows = parse_table(tbl)

    # Column indices to update (robust matching against header variants)
    def _find_col(name_parts: List[str]) -> int:
        for idx, col in enumerate(header):
            s = col.lower()
            if all(part in s for part in name_parts):
                return idx
        raise ValueError(f"Column with parts {name_parts} not found in header: {header}")

    try:
        col_strategy = header.index("Estratégia")
    except ValueError as e:
        raise RuntimeError("Expected 'Estratégia' column not found in the table header") from e

    try:
        # Match either "Turnover (mediana)" or "Turnover mediano (‖Δw‖₁)"
        col_turn_med = _find_col(["turnover", "median"])
    except ValueError:
        try:
            col_turn_med = _find_col(["turnover", "mediana"])  # pt-BR
        except ValueError as e:
            raise RuntimeError("Turnover median column not found (mediana/mediano)") from e

    try:
        col_turn_p95 = _find_col(["turnover", "p95"])
    except ValueError as e:
        raise RuntimeError("Turnover p95 column not found") from e

    # Mapping from README display names to summary strategy keys
    display_to_key = {
        "Equal-Weight 1/N": "equal_weight",
        "Risk Parity (ERC)": "risk_parity",
        "60/40 Stocks/Bonds": "sixty_forty",
        "Hierarchical Risk Parity (HRP)": "hrp",
        "Minimum Variance (Ledoit-Wolf)": "min_variance_lw",
        "MV Huber": "mv_huber",
        "MV Shrunk50": "shrunk_mv",
        "MV Shrunk20": "shrunk_20",
    }

    updated = 0

    for i, row in enumerate(rows):
        name = row[col_strategy]
        # PRISM-R handled separately
        if name.startswith("PRISM-R"):
            if prism_stats is None:
                continue
            med_val, p95_val = prism_stats
            current_med = row[col_turn_med]
            current_p95 = row[col_turn_p95]
            print(f"[DEBUG] Updating PRISM-R: current_med='{current_med}', current_p95='{current_p95}', "
                  f"new_med='{fmt_sci(med_val)}', new_p95='{fmt_sci(p95_val)}', force={force_overwrite}")
            if force_overwrite or current_med in ("—", "", "-"):
                row[col_turn_med] = fmt_sci(med_val)
            if force_overwrite or current_p95 in ("—", "", "-"):
                row[col_turn_p95] = fmt_sci(p95_val)
            updated += 1
            rows[i] = row
            continue

        # Baseline mapping
        key = display_to_key.get(name)
        if key is None:
            # Unknown row; skip
            continue
        stats = summary_map.get(key)
        if stats is None:
            # Not available in summary
            continue
        med_val, p95_val = stats
        current_med = row[col_turn_med]
        current_p95 = row[col_turn_p95]
        print(f"[DEBUG] Updating {name} (key={key}): current_med='{current_med}', current_p95='{current_p95}', "
              f"new_med='{fmt_sci(med_val)}', new_p95='{fmt_sci(p95_val)}', force={force_overwrite}")
        if force_overwrite or current_med in ("—", "", "-"):
            row[col_turn_med] = fmt_sci(med_val)
        if force_overwrite or current_p95 in ("—", "", "-"):
            row[col_turn_p95] = fmt_sci(p95_val)
        updated += 1
        rows[i] = row

    # Rebuild and write back
    new_tbl_lines = rebuild_table(header, rows, tbl)
    new_text = text[:start] + new_tbl_lines + text[end:]
    readme_path.write_text("\n".join(new_text) + "\n", encoding="utf-8")
    return updated


def main() -> None:
    ap = argparse.ArgumentParser(description="Update README table 5.1 with turnover median and p95")
    ap.add_argument("--readme", type=Path, default=DEFAULT_README, help="Path to README.md")
    ap.add_argument(
        "--summary",
        type=Path,
        default=DEFAULT_SUMMARY,
        help="CSV with baseline turnover distribution stats (strategy, turnover_median, turnover_p95)",
    )
    ap.add_argument(
        "--per-window-prism",
        type=Path,
        default=DEFAULT_PER_WINDOW_PRISM,
        help="CSV with PRISM-R per-window results (Window End, Turnover)",
    )
    ap.add_argument(
        "--prism-trades",
        type=Path,
        default=DEFAULT_PRISM_TRADES,
        help="CSV with PRISM-R trade-level turnover (date, turnover)",
    )
    ap.add_argument(
        "--oos-config",
        type=Path,
        default=DEFAULT_OOS_CONFIG,
        help="YAML with OOS start_date/end_date (configs/oos_period.yaml)",
    )
    ap.add_argument(
        "--force-overwrite",
        action="store_true",
        help="If set, overwrite existing values (not only dashes/placeholders)",
    )
    args = ap.parse_args()

    # Load inputs
    oos = load_oos_period(args.oos_config)
    summary_map = load_baseline_summary(args.summary)
    prism_stats = compute_prism_turnover_from_trades(args.prism_trades, oos)
    if prism_stats is None:
        prism_stats = compute_prism_turnover_from_windows(args.per_window_prism, oos)

    print(f"[DEBUG] README path: {args.readme}")
    print(f"[DEBUG] Summary CSV: {args.summary} (exists={args.summary.exists()})")
    print(f"[DEBUG] Baseline summary keys: {sorted(list(summary_map.keys()))}")
    print(f"[DEBUG] PRISM turnover stats: {prism_stats}")
    updated = update_readme_table(
        readme_path=args.readme,
        summary_map=summary_map,
        prism_stats=prism_stats,
        force_overwrite=args.force_overwrite,
    )
    print(f"[DEBUG] Updated rows: {updated}")


if __name__ == "__main__":
    main()
